# 기술 면접 정리

## AI
### 머신러닝(Machine Learning)
인공 지능의 한 분야로, 컴퓨터가 학습 모형을 기반으로 주어진 데이터를 통해 스스로 학습하고 개선하도록 함. 데이터마이닝과 많은 기법이 중첩되어 사용되지만, 머신러닝의 경우 새로운 데이터에 적용해 결과를 에측하는 일반화에 좀 더 치중하는 것이 데이터를 해석하는 것에 집중하는 데이터 마이닝과의 차이

### 강화학습(Reinforcement Learning)
머신러닝의 한 영역으로, 어떤 환경 안에서 선택 가능한 행동들 중 보상을 최대화하는 행동이나 행동 순서를 선택 하도록 하는 학습 모형. 행동심리학에서 영감을 받아 제안됨. 일반적으로 학습 데이터가 제시되지 않으며, 최적화 문제에 많이 활용

## 통계
### 비모수 통계, 비모수 검정(Non-parametric Statistics, NPAR Testing)
모수에 대한 가정을 전제로 하는 전통적인 통계 분석 방법과 달리, 모집단의 분포에 대한 가정 없이 주어진 데이터에서 직접 확률을 계산하여 통계 검증을 하는 분석법. 정규 분포를 따르지 않거나 근사할 수 없는 데이터, 표본이 적은 데이터에서도 적용할 수 있는 방법이 존재함. 순위, 중앙값 등 활용하는 경우가 많음

### 신뢰구간(Cofidence Interval)
모수가 어느 범위 안에 있는지를 확률적으로 보여주는 방법. 표본에서 얻은 통계량으로 모수를 추정 할 때 신뢰 하한과 신뢰 상한 사이의 구간으로 추정하는 구간 추정의 방법으로 하나의 추정치를 도출 할 때 신뢰 하한과 신뢰 상한 구간으로 추정하는 구간 추정의 방법으로 하나의 추정치를 도출 하는 점 추정보다 실무에서 더 유용함

### 중심극한정리(CLT, Central Limit Theorem)
동일한 확률분포를 가진 독립 확률 변수 n개의 평균의 분포는 n이 적당히 크다면 정규분포에 가까워 진다는 정리. n은 통상적으로 30 이상일 때 적당히 크다고 판단하며, 다양한 추론 통계학 방법들을 사용하는 근거로 활용됨.

### 자유도(DF, Degrees of Freedom)
통계적 추정을 할 때 표본자료 중 모집단에 대한 정보를 주는 독립적인 자료의 수를 의미. (독립적으로 자유롭게 바뀔 수 있는 값의 수) 일반적으로 표본 수에서 제약조건의 수 또는 추정해야 하는 모수의 개수를 빼서 얻을 수 있음. 일부 확률 분포는 자유도에 따라 분포의 모양이 결정됨 (ex. 카이제곱 분포)

### 독립성(Independent)
확률론에서는 한 사건이 일어날 확률이 다른 사건이 일어날 확률에 영향을 미치지 않는다는 의미. 데이터에서는 하나의 특성이 다른 요소에 영향을 미치지 않는다(연관성이 없다)는 의미로도 많이 사용됨

### 이상값, 이상치(OUtlier)
다른 자료와는 극단적으로 크거나 작은 관측값. 산점도나 상자도표 같은 시각화 방법 또는 ESD나 IQR을 활용한 기준치로 판단할 수 있음. 데이터 분석에서 이상값의 존재는 결과를 왜곡할 수 있기 떄문에 전처리 및 탐색 과정에서 제거, 조정(치환) 등의 방법으로 처리하거나, 비모수적 방법으로 분석하는 것이 적절함.

### 변동계수(CV, Coefficient of Variation)
표준편차를 평균으로 나눈 값으로, 측정의 단위와 무관하기 때문에 여러 데이터의 산포도(Dispersion)을 비교할 때 유용함.

### MECE(Mutually Exclusive and Collectively Exhaustive)
전체 집합을 중복되지 않고 누락되지도 않은 부분집합으로 생각해서, 각각의 합이 전체가 되게 하는 분석적 구조. 각각의 집합은 중복되지 않으며(상호배제, Mutually Exclusive), 모든 집합을 합했을 때 전체에서 빠지는 것도 없어야(전체적으로 완전, Collectively Exhaustive) 함. 데이터를 통해 문제의 원인을 파악하는 과정에서 유용한 사고

### 중앙값(Median)
평균과 함께 데이터의 중심을 나타내는 중심 경향지로 자주 사용되는 대표값. 관측치를 크기순으로 나열했을 때, 한가운데 위치하는 값. 이상값에 민감하다는 평균의 한계를 보완할 수 있는 대푯값으로 데이터가 비대칭적이거나 이상값이 많을 때 유용함. 비모수 통계에서는 평균의 대안으로도 많이 활용

### 통계량(Statistic)
표본 데이터를 이용해 계산하는 수치로, 모집단(Population)의 특성을 타나내는 모수를 추정하는 과정에서 활용됨. 표본 통계량의 확률 분포를 표본 분포라고 함

### 불편추정량(Unviased Estimator)
표본으로부터 모수를 추정하는 추정량중에서, 추정량의 기댓값이 모수와 같은 경우가 추정량을 불편 추정량이라 함. 추정량의 기댓값이 모수와 다른 경우는 편향이 있기 때문에 편의 추정량라고 함. 일반적으로는 불편 추정량이 편의 추정량보다 모수의 추정에 적합함.

### 기술통계학(Descriptive Statistics)
측정이나 실험에서 수집한 데이터의 정리, 요약, 해석, 표현 등을 통해 그 표본이나 데이터의 특성을 규명하고 설명하여 이해할 수 있도록 하는 통계적 방법론

### 사전확률(Piror Probability)
특정 사상이 일어나기 전의 확률로 베이즈 추론에서 관측자가 관측을 하기 전에 가지고 있는 확률 분포, 사전 확률과 가능도(우도)가 주어지면 베이즈 정리를 통해 사후 확률을 얻을 수 있음.

### 우도, 가능도(Likelihood)
확률 분포의 모수가, 어떤 확률변수 표본과 일관 되는 정도를 나타내는 척도로 얼마나 그럴듯한 (가능성 높은)지를 확인할 수 있음. 주어진 표집값(표본)에 대한 모수의 가능도는 이 모수를 따르는 분포가 주어진 관측값에 부여하는 확률. 우도가 높은 높은 통계량을 얻는 것은 모집단의 추론이라는 추론 통계학의 목표를 생각할 때 매우 중요함.

### 기댓값(Expected Value)
어떤 확률 과정을 무한히 반복했을 때, 얻을 수 있는 값의 평균으로서 개대할 수 있는 값. 각 사건이 벌어졌을 때의 이득과 그 사건이 벌어질 확률을 곱한 것을 전체 사건에 대해 합한 값.

### 대푯값(Representative Value)
어떤 데이터(표본)를 대표하는 값을 대푯값이라 함. 중심을 설명하는 값은 중심 경향치라 하며 대표적으로 평균, 중앙값, 최빈값 등을 들 수 있고, 자료의 값들이 흩어진 정도를 대표하는 산포도에는 대표적으로 범위, 분산, 백분위수 등이 있음. 분포의 모양을 대표하는 왜도, 첨도 역시 빈번하지 않지만 종종 사용되는 대푯값

## 왜도(Skewness)
자료의 비대칭적인 분포 정도를 표현하는 대푯값으로 왜도가 0이면 좌유가 대칭인 분포를 의미함. 왜도가 큰 양수일수록 우측 꼬리가 길어지므로 우측에 더 많이 퍼지고 음수일수록 좌측꼬리가 긴 분포를 나타냄.

## 첨도(Kurtosis)
분포의 꼬리가 두꺼운 정도(얼마나 뾰족한지의 정도)를 나타내는 대푯값. 관측값이 얼마나 중심에 몰려있는지 또는 퍼져있는지 측정할 때 사용. 3에 가까우면 정규분포와 같은 모양을 가지며, 3보다 크면 정규분포보다 꼬리가 두꺼운 분포를 갖게 됨.

### 최소제곱법(Least Squares Method)
관측된 데이터와 평균의 오차를 제곱해서 더한 제곱합이 가장 작아지도록 모형을 만드는 방법. 선형회귀분석에서는 가능한 여러 직선들 중 관측 데이터에 가장 가까운(오차합이 적은) 공식을 찾는 방법

### 평균제곱오차(MSE, Mean Squared Error)
예측 모델의 성능을 평가하는 척도 중 하나로, 실제 관측값과 모형이 예측한 값의 차이를 제곱하여 예측 정확성을 측정하는 것. 오차 제곱합을 전체 데이터의 개수 n으로 나눠서 계산하며 에측하는 Y값이 연속형이 경우에 주로 MSE가 사용됨

### 등분산성(Homoscedasticity)
분산이 동일한지를 의미하는데 일반적으로 회귀분석을 포함한 다양한 통계 분석 방법에서 가정으로 요구되는 잔차의 분산이 동일한지를 나타냄. 예측값에 대한 잔차를 그린 Residual Plot으로 확인할 수 있음. 등분산성이 위배된다고 판단되면 기본 가정을 만족하지 못하므로 정규화나 이를 해소할 수 있는 분석 방법을 고려해야 함

### 이동평균(Moving Average)
전체 데이터 집합에서 연속된 일련의 데이터 평균을 만들어내는 계산으로 롤링 평균(Rolling Mean)이라고 함. 동일한 가중치가 적용되는 단순 이동평균의 대표적 사례는 주식 시장에서 n일 동안의 주식 종가로 계산한 것.

### 협업 필터링(Collaborative Filtering)
다수의 사용자 데이터를 활용하여 사용자가 좋아할 만한 대상을 예측하는 방법으로, 데이터에서 확인된 과거의 선호 경향이 미래에도 유지될 것이라는 전제에 따름. 유저 기반의 협업 필터링과 아이템 기반의 협업 필터링으로 나뉠 수 있으며 많은 추천 시스템의 근간이 되었던 방법.


















